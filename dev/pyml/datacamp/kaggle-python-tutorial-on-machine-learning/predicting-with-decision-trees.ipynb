{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Python Tutorial on Machine Learning\n",
    "https://www.datacamp.com/community/open-courses/kaggle-python-tutorial-on-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting-with-decision-trees\n",
    "https://campus.datacamp.com/courses/kaggle-python-tutorial-on-machine-learning/predicting-with-decision-trees?ex=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "kaggle_path = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/\"\n",
    "\n",
    "# Load the train and test datasets to create two DataFrames\n",
    "train_url = kaggle_path + \"train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "\n",
    "test_url = kaggle_path + \"test.csv\"\n",
    "test = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro to decision trees\n",
    "    In the previous chapter, you did all the slicing and dicing yourself to find subsets that have a higher chance of surviving. A decision tree automates this process for you and outputs a classification model or classifier.\n",
    "\n",
    "    Conceptually, the decision tree algorithm starts with all the data at the root node and scans all the variables for the best one to split on. Once a variable is chosen, you do the split and go down one level (or one node) and repeat. The final nodes at the bottom of the decision tree are known as terminal nodes, and the majority vote of the observations in that node determine how to predict for new observations that end up in that terminal node.\n",
    "\n",
    "    First, let's import the necessary libraries:\n",
    "\n",
    "### Instructions\n",
    "    Import the numpy library as np\n",
    "    From sklearn import the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the Numpy library\n",
    "import numpy as np\n",
    "\n",
    "# Import 'tree' from scikit-learn library\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning and Formatting your Data\n",
    "    Before you can begin constructing your trees you need to get your hands dirty and clean the data so that you can use all the features available to you. In the first chapter, we saw that the Age variable had some missing value. Missingness is a whole subject with and in itself, but we will use a simple imputation technique where we substitute each missing value with the median of the all present values.\n",
    "    train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "    \n",
    "    Another problem is that the Sex and Embarked variables are categorical but in a non-numeric format. Thus, we will need to assign each class a unique integer so that Python can handle the information. Embarked also has some missing values which you should impute witht the most common class of embarkation, which is \"S\".\n",
    "\n",
    "### Instructions\n",
    "    Assign the integer 1 to all females\n",
    "    Impute missing values in Embarked with class S. Use .fillna() method.\n",
    "    Replace each class of Embarked with a uniques integer. 0 for S, 1 for C, and 2 for Q.\n",
    "    Print the Sex and Embarked columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "print(train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impute the Embarked variable\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna('S')\n",
    "\n",
    "# Convert the Embarked classes to integer form\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "\n",
    "#Print the Sex and Embarked columns\n",
    "print(train['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
