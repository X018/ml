{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow学习笔记（2）：多元线性回归\n",
    "https://segmentfault.com/a/1190000007969901"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前言\n",
    "本文使用tensorflow训练多元线性回归模型，并将其与scikit-learn做比较。数据集来自Andrew Ng的网上公开课程[Deep Learning](http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=DeepLearning&doc=exercises/ex3/ex3.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of sklean: K=[  139.21072388 -8738.02148438], b=89597.805854\n",
      "[ 2000.6809082      3.17021275] [  7.86202576e+02   7.52842903e-01]\n",
      "0 [ 31729.23632812  16412.6484375 ] [ 102123.7890625]\n",
      "10 [ 97174.78125      5595.25585938] [ 333681.59375]\n",
      "20 [ 106480.5703125    -3611.31201172] [ 340222.53125]\n",
      "30 [ 108727.5390625    -5858.10302734] [ 340407.28125]\n",
      "40 [ 109272.953125     -6403.52148438] [ 340412.5]\n",
      "50 [ 109405.3515625    -6535.91503906] [ 340412.625]\n",
      "60 [ 109437.4921875    -6568.05371094] [ 340412.625]\n",
      "70 [ 109445.296875     -6575.85644531] [ 340412.625]\n",
      "80 [ 109447.1875       -6577.75097656] [ 340412.625]\n",
      "90 [ 109447.640625     -6578.20654297] [ 340412.625]\n",
      "Coefficients of tensorflow(input should be standardized): K=[ 109447.7421875    -6578.31152344], b=[ 340412.625]\n",
      "Coefficients of tensorflow(raw input): K=[  139.21061707 -8737.9609375 ], b=[ 89597.78125]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_data = np.loadtxt(\"input/ex3x.dat\").astype(np.float32)\n",
    "y_data = np.loadtxt(\"input/ex3y.dat\").astype(np.float32)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x_data, y_data)\n",
    "print(\"Coefficients of sklean: K=%s, b=%f\" % (reg.coef_, reg.intercept_))\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_data)\n",
    "print(scaler.mean_, scaler.scale_)\n",
    "\n",
    "x_data_standard = scaler.transform(x_data)\n",
    "\n",
    "W = tf.Variable(tf.zeros([2,1]))\n",
    "b = tf.Variable(tf.zeros([1,1]))\n",
    "y = tf.matmul(x_data_standard, W) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - y_data.reshape(-1, 1))) / 2\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.3)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train)\n",
    "    if step % 10 == 0:\n",
    "        print(step, sess.run(W).flatten(), sess.run(b).flatten())\n",
    "        \n",
    "print(\"Coefficients of tensorflow(input should be standardized): K=%s, b=%s\"\n",
    "     % (sess.run(W).flatten(), sess.run(b).flatten()))\n",
    "print(\"Coefficients of tensorflow(raw input): K=%s, b=%s\"\n",
    "      % (sess.run(W).flatten() / scaler.scale_, \n",
    "         sess.run(b).flatten() - np.dot(scaler.mean_ / scaler.scale_,\n",
    "                                       sess.run(W))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思考\n",
    "对于梯度下降算法，变量是否标准化很重要。在这个例子中，变量一个是面积，一个是房间数，量级相差很大，如果不归一化，面积在目标函数和梯度中就会占据主导地位，导致收敛极慢。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
